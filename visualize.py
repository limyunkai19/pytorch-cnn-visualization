import json, copy
import numpy as np
from PIL import Image
import matplotlib.cm as Pltcolormap
from matplotlib import pyplot as PLT

import torch, torchvision
import torch.nn.functional as F
from torchvision import transforms
from torch.autograd import Variable


def one_hot_tensor(idx, length):
    one_hot = torch.FloatTensor(1, length).zero_()
    one_hot[0][idx] = 1.0
    return one_hot

class GradCAM:
    def __init__(self, model, transform, target_layer, cuda=False):
        self.model = copy.deepcopy(model)
        self.model.train(False)
        self.cuda = cuda
        if self.cuda:
            self.model.cuda()
        self.transform = transform
        self.target_layer = target_layer

        # define hook function
        def forward_hook(module, input, output):
            self.feature_maps = output.data

        def backward_hook(module, grad_input, grad_output):
            self.gradients = grad_output[0].data

        # register hook function
        for name, module in self.model.named_modules():
            if name == self.target_layer:
                module.register_forward_hook(forward_hook)
                module.register_backward_hook(backward_hook)

    def forward(self, img):
        """ The forward pass

        Argument:
            img (Tensor) - the (unprocessed) input image

        Return:
            Tensor/Dict
        """

        # preprocess the PIL image first
        img_tensor = preprocess(img)
        img_tensor.unsqueeze_(0) # this add a dimension as a dummy "batch"
        img_variable = Variable(img_tensor)
        self.output = self.model(img_variable)
        return self.output.data


    def backward(self, idx, sorted=False):
        """ The (partial) backward pass and generate GradCAM intensity value for each pixel

        Argument:
            idx (int) - the idx of the class to be localize by GradCAM
            sorted (bool) - if sorted==True, the idx[0] will be the class with highest score,
                idx[1] will be the class with second highest score and so on

        Return:
            Tensor (size == kernal size of target layer)
                - GradCAM intensity value for each pixel
        """

        self.model.zero_grad()
        #implement sorted !!!
        self.output.backward(gradient=one_hot_tensor(idx, 1000), retain_graph=True)

        # self.feature_maps # 1x2048x7x7
        # self.gradients # 1x2048x7x7

        # GAP = torch.nn.AvgPool2d(self.gradients.size()[2:])
        weights = F.avg_pool2d(Variable(self.gradients), kernel_size=self.gradients.size()[2:]).data

        gradCAM_intensity = torch.FloatTensor(self.feature_maps.size()[2:]).zero_()

        for feature_map, weight in zip(self.feature_maps[0], weights[0]):
            gradCAM_intensity += feature_map * weight

        #relu
        gradCAM_intensity.clamp_(min=0)

        return gradCAM_intensity

    @staticmethod
    def apply_color_map(intensity, img):
        """ Apply the color map on the original image with GradCAM intensity value generated
            by GradCAM.backward()

        Argument:
            intensity (Tensor) - GradCAM intensity value generated by GradCAM.backward()
            img (PIL image) - The image that GradCAM intensity were to be apply to,
                suppose to be the original image

        Return:
            PIL image - The img with GradCAM intensity applied to
            Numpy array - The intensity same size as img (range: [0-1])
        """

        # normalize
        intensity -= intensity.min()
        intensity /= intensity.max()

        # use PIL bilinear resize interpolation
        # note: *255 -> resize -> /255.0 (divide for heat map input[0,1]) is === resize
        pil = Image.fromarray(intensity.cpu().numpy())
        pil = pil.resize(img.size, resample=Image.BILINEAR)
        intensity = np.asarray(pil)

        # get the color map from matplotlib
        color_map = Pltcolormap.get_cmap('jet')
        heat_map = color_map(intensity)
        heat_map[:,:,3] /= 2.0
        heat_map *= 255

        original_img = np.asarray(img)

        return Image.fromarray(np.uint8((heat_map[:,:,:3]+original_img)/2.0)), intensity


class Backpropagation:
    """
    Vanilla Backpropagation.
    Backpropagate to input then get the gradient at input
    """

    def __init__(self, model, transform, cuda=False):
        self.model = copy.deepcopy(model)
        # self.model = model
        self.model.train(False)
        self.cuda = cuda
        if self.cuda:
            self.model.cuda()
        self.transform = transform

    def forward(self, img):
        """ The forward pass

        Argument:
            img (Tensor) - the (unprocessed) input image

        Return:
            Tensor/Dict
        """

        img_tensor = preprocess(img)
        img_tensor.unsqueeze_(0) # this add a dimension as a dummy "batch"
        img_variable = Variable(img_tensor, requires_grad=True)

        self.input = img_variable
        self.output = self.model(img_variable)
        return self.output.data


    def backward(self, idx, sorted=False):
        """ The backward pass and return the gradient at input image

        Argument:
            idx (int) - the idx of the class to be localize by GradCAM
            sorted (bool) - if sorted==True, the idx[0] will be the class with highest score,
                idx[1] will be the class with second highest score and so on

        Return:
            PIL image - The gradient value for each pixel
        """

        self.model.zero_grad()
        #implement sorted !!!
        self.output.backward(gradient=one_hot_tensor(idx, 1000), retain_graph=True)

        gradient = self.input.grad.data
        gradient -= gradient.min()
        gradient /= gradient.max()
        gradient *= 255

        # 1x3x224x224 -> 224x224x3
        gradient = gradient.cpu().numpy()[0].transpose(1, 2, 0)

        return Image.fromarray(np.uint8(gradient))

class GuidedBackpropagation(Backpropagation):
    """
    Guided Backpropagation

    x.grad or img.grad is what we wanted
    GuidedBackprop === input>0 * gradin>0 * gradin on relu.backward
    but original relu had implemented relu gradin = input>0 * gradin
    thus we only need to add gradin>0 * relu gradin
    """

    def __init__(self, model, transform, cuda=False):
        super().__init__(model, transforms, cuda)

        # define hook function
        def backward_hook(module, grad_input, grad_output):
            # Guided Backpropagation
            # Only allows positive gradient to backflow
            return (torch.clamp(grad_input[0], min=0.0),)

        # register hook function on relu module
        for name, module in self.model.named_modules():
            if isinstance(module, torch.nn.ReLU):
                module.register_backward_hook(backward_hook)

class GuidedGradCAM:
    def __init__(self, model, transform, target_layer, cuda=False):
        self.model = model
        self.cuda = cuda
        self.transform = transform
        self.target_layer = target_layer

        self.GradCAM = GradCAM(model, transforms, target_layer, cuda)
        self.GuidedBackprop = GuidedBackpropagation(model, transforms, cuda)

    def forward(self, img):
        """ The forward pass

        Argument:
            img (Tensor) - the (unprocessed) input image

        Return:
            Tensor/Dict
        """
        pass


if __name__ == '__main__':
    resnet = torchvision.models.resnet152(pretrained=True)
    preprocess = transforms.Compose([
       # transforms.Scale(256),
       transforms.CenterCrop(224),
       # transforms.Scale(224),
       transforms.ToTensor(),
       transforms.Normalize(
           mean=[0.485, 0.456, 0.406],
           std=[0.229, 0.224, 0.225]
        )
    ])
    class_name = json.load(open('data/class_name.json', 'r'))

    import sys
    if len(sys.argv) < 2:
        print("usage: python visualize.py path/to/image")
        exit()

    img_pil = Image.open(sys.argv[1])
    img_pil = img_pil.resize((224, 224))

    gradcam = GradCAM(resnet, preprocess, "layer4.2")
    guidedbackprop = GuidedBackpropagation(resnet, preprocess)
    backprop = Backpropagation(resnet, preprocess)

    # all x should be the same
    x = gradcam.forward(img_pil)
    x = guidedbackprop.forward(img_pil)
    x = backprop.forward(img_pil)

    score = x.cpu().numpy()[0]

    # get the top 3 prediction
    print("Top 3 prediction")
    for i in range(3):
        idx = score.argmax()
        intensity = gradcam.backward(idx)
        gradcam_img, gradcam_intensity = gradcam.apply_color_map(intensity, img_pil)

        gbackprop_img = guidedbackprop.backward(idx)
        # guidedbackprop.backward(idx1).convert('L').save('gb.png')

        backprop_img = backprop.backward(idx)


        gbackprop_arr = np.array(gbackprop_img.convert("L"), dtype='float')
        # gbackprop_arr -= gbackprop_arr.min()
        # gbackprop_arr /= gbackprop_arr.max()

        g_gradcam = gbackprop_arr*gradcam_intensity

        g_gradcam_img = Image.fromarray(g_gradcam)

        print(idx, score[idx], class_name[idx])

        img = [gradcam_img, gbackprop_img, backprop_img, g_gradcam_img]
        title = ["Grad-CAM", "Guided Backpropagation", "Backpropagation", "Guided Grad-CAM"]
        fig = PLT.figure(class_name[idx].split(",")[0])

        for i in range(4):
            ax = fig.add_subplot(221+i)
            ax.axis('off')
            ax.imshow(img[i])
            ax.set_title(title[i])

        PLT.suptitle(class_name[idx]+" Score: "+str(x[0][idx])[:5], fontsize=18)
        PLT.show()

        score[idx] = -1000
